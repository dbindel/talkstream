<!DOCTYPE html>
<html lang="en">

  <head>
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8' />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Web stream</title>
  <meta name="description" content="Web site of the SIAM Activity Group on Linear Algebra.
">

   <link href="/" rel="alternate" title="SIAG-LA" type="application/atom+xml" />

  <link rel="stylesheet" href="/css/layouts/pure-min.css">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css">

  <!--[if lte IE 8]>
      <link rel="stylesheet" href="/css/layouts/side-menu-old-ie.css">
      <link rel="stylesheet" href="/css/layouts/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
      <link rel="stylesheet" href="/css/layouts/grids-responsive-min.css">
      <link rel="stylesheet" href="/css/layouts/side-menu.css">
  <!--<![endif]-->

  <link rel="shortcut icon" href="http://www.siam.org/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="http://siags.siam.org//">

  
  <!-- mathjax config similar to math.stackexchange -->
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [['$', '$']],
          displayMath: [['$$', '$$']],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  

  
  <!-- jquery from CDN -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  <link rel="stylesheet" href="//ajax.googleapis.com/ajax/libs/jqueryui/1.11.2/themes/smoothness/jquery-ui.css" />
  <script src="//ajax.googleapis.com/ajax/libs/jqueryui/1.11.2/jquery-ui.min.js"></script>
  <script src="/js/filtering.js"></script>
  

</head>


  <body>
    <div id="layout">

      <!-- Menu toggle -->
<a href="#menu" id="menuLink" class="menu-link">
  <!-- Hamburger icon -->
  <span></span>
</a>

<div id="menu">
  <div class="pure-menu pure-menu-open">
    <a class="pure-menu-heading" href="#">Web stream</a>
    
    <ul>
      <li>
        <a href="/index.html">Home</a>
      </li>
      <li>
        <a href="/about.html">About</a>
      </li>
      <li>
        <a href="/meetings/">Conferences</a>
      </li>
      <li>
        <a href="/news.html">Newsletter</a>
      </li>
      <li>
        <a href="/prizes.html">Prizes</a>
      </li>
      <li>
        <a href="/related.html">Related</a>
      </li>
    </ul>
  </div>
</div>


      <div id="main">
        <div class="header">
          <h1>Web Stream</h1>
<h2>Talks</h2>

        </div>

        <div class="content">
          

<button class="pure-button" style="font-size: 70%;" id="button-all">All</button>

<button class="pure-button" style="font-size: 70%;" id="button-Cornell">Cornell</button>

<button class="pure-button" style="font-size: 70%;" id="button-Berkeley">Berkeley</button>

<button class="pure-button" style="font-size: 70%;" id="button-Stanford">Stanford</button>

<button class="pure-button" style="font-size: 70%;" id="button-MIT">MIT</button>

<button class="pure-button" style="font-size: 70%;" id="button-Temple">Temple</button>

<button class="pure-button" style="font-size: 70%;" id="button-VA Tech">VA Tech</button>

<button class="pure-button" style="font-size: 70%;" id="button-NCSU">NCSU</button>

<button class="pure-button" style="font-size: 70%;" id="button-Oxford">Oxford</button>

<button class="pure-button" style="font-size: 70%;" id="button-Manchester">Manchester</button>



<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-12-01-cornell-scan.html">Chebfun2 and global spectral methods for PDEs using low rank ideas.</a>
    <!-- <a href="/talks/2014-12-01-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-townsend-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://math.mit.edu/~ajt/">Alex Townsend</a>
    (Math, MIT)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    01 Dec 2014
  </p>
  <div class="blurb"> 
  <p>Chebfun2 is an extension of Chebfun to 2D scalar- and vector-valued 
functions defined on rectangles. The main approximation scheme 
relies on a iterative variant of Gaussian elimination on functions 
to compute low rank approximants. Related low rank ideas are now 
employed on partial differential operators, which has allowed us to 
extend a well-conditioned spectral method for ODEs to a fast and 
spectrally accurate PDE solver. Some PDEs requiring over a million
degrees of freedom can be now be solved in under a second. Software 
is publicly available as part of Chebfun.</p>

  </div>
</div>

<div class="series-mit-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-24-mit-amc.html">Numerical Computations in Random Matrix Theory</a>
    <!-- <a href="/talks/2014-11-24-mit-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www-math.mit.edu/amc/fall14/olver.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.maths.usyd.edu.au/u/olver/">Sheehan Olver</a>
    (University of Sydney)<br/>
    
    MIT Applied Math Colloquium,
    
    24 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Random matrix theory has undergone significant theoretical progress in the last
two decades, including proofs on universal behaviour of eigenvalues as the
matrix dimension becomes large, and a deep connection between algebraic
manipulations of random matrices and free probability theory. Underlying many
of the analytical advances are tools from complex analysis. By developing
numerical versions of these tools, it is now possible to calculate random
matrix statistics to high accuracy and sample from a broader class of unitary
ensembles, leading to new conjectures on the behaviour of random matrices.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-24-cornell-scan.html">New directions in spectral methods.</a>
    <!-- <a href="/talks/2014-11-24-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-driscoll-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.udel.edu/~driscoll/">Tobin Driscoll</a>
    (Math, U. of Delaware)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    24 Nov 2014
  </p>
  <div class="blurb"> 
  <p>What if all you had to do to solve a differential equation was to write it down? The development of the Chebfun project for numerical computing of functions has sparked an interest in making this idea a reality. This aim has led to new applications and understanding in spectral methods of automatic differentiation, separation of approximation and residual spaces, and splitting of the domain. For a great variety of interesting problems, the goal of automatic and accurate computation of solutions has been achieved in one dimension. Challenges remain in adaptation for singularly perturbed problems, very large systems of equations, unbounded domains, and time-dependent problems. Progress into multiple dimensions is underway, with many unanswered questions at the outset.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-21-vt-am-colloq.html">Non-Markovian Reduced Equations for Stochastic PDEs</a>
    <!-- <a href="/talks/2014-11-21-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/nov21.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://honghuliu.bol.ucla.edu/">Honghu Liu</a>
    (UCLA)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    21 Nov 2014
  </p>
  <div class="blurb"> 
  <p>In this talk, a new approach to deal with the parameterization problem of the
small spatial scales by the large ones for stochastic partial differential
equations will be discussed. This approach relies on stochastic parameterizing
manifolds (PMs) which are random manifolds aiming to provide—in a mean square
sense—approximate parameterizations of the small scales by the large ones.
Backward-forward systems will be introduced to give access to such PMs as
pullback limits depending on the time history of certain approximations of the
low modes dynamics. It will be shown that the corresponding pullback limits can
be efficiently determined in practice, leading in turn to an operational
procedure for the derivation of non-Markovian reduced equations able to achieve
good modeling performances. A stochastic Burgers-type equation will serve to
illustrate that the memory effects conveyed by such reduced systems play a key
role to capture noise-induced transitions or large excursions caused by the
noise.</p>


  </div>
</div>

<div class="series-manchester-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-21-manchester-nas.html">50 Years of Time Parallel Time Integration</a>
    <!-- <a href="/talks/2014-11-21-manchester-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.maths.manchester.ac.uk/our-research/events/seminars/numerical-analysis-and-scientific-computing/50-years-of-time-parallel-time-integration.htm"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.unige.ch/~gander/">Martin Gander</a>
    (University of Geneva)<br/>
    
    Manchester Numerical Analysis Seminar,
    
    21 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Time parallel time integration methods have received renewed interest over the
last decade because of the advent of massively parallel computers, which is
mainly due to the clock speed limit reached on today’s processors. When solving
time dependent partial differential equations, the time direction is usually
not used for parallelization. But when parallelization in space saturates, the
time direction offers itself as a further direction for parallelization.  The
time direction is however special, and for evolution problems there is a
causality principle: the solution later in time is affected (it is even
determined) by the solution earlier in time, but not the other way round.
Algorithms trying to use the time direction for parallelization must therefore
be special, and take this very different property of the time dimension into
account.</p>

<p>I will show in this talk how time domain decomposition methods were invented,
and give an overview of the existing techniques. Time parallel methods can be
classified into four different groups: methods based on multiple shooting,
methods based on domain decomposition and waveform relaxation, space-time
multigrid methods and direct time parallel methods. I will show for each of
these techniques the main inventions over time by choosing specific
publications and explaining the core ideas of the authors. This talk is for
people who want to quickly gain an overview of the exciting and rapidly
developing area of research of time parallel methods.</p>


  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-21-cornell-cam.html">Models, Contracts and Control That Help Electricity Consumers to Help the Grid</a>
    <!-- <a href="/talks/2014-11-21-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_duncan_callaway_uc_berkeley_-_models_contracts_and_control_that_help_electricity_consumers_to_help_the_grid"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://citris-uc.org/person/professor-duncan-callaway/">Duncan Callaway</a>
    (UC Berkeley)<br/>
    
    Cornell Applied Math Colloquium,
    
    21 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Power system operators have dealt with variability and uncertainty in power
demand since the days of Edison and Westinghouse. However as we add greater
amounts of production from wind- and solar-powered generators, net variability
and uncertainty is growing significantly, and status quo operating strategies
will not scale to the kinds of systems we need to decarbonize society. This
talk goes into detail on how we can use electricity demand flexibility to
absorb some of this new variability and uncertainty. I’ll first discuss ways to
model and control some classes of electricity loads at the level of power
system operators while ensuring the end-use service (e.g. thermal comfort)
remains met. The specific approach uses Markov chain models to describe the
temperature state evolution of populations of TCLs, and Kalman filtering for
both state and joint parameter/state estimation. Then I’ll discuss ways to
think about structuring financial contracts between customers and utilities to
elicit this flexibility. The details of the approach involve formulating the
contract design problem as mean-variance constrained risk- sensitive control
that can be solved – after a few transformations – with a dynamic programming
approach.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-19-ucb-lapack.html">Distances Between Subspaces of Different Dimensions</a>
    <!-- <a href="/talks/2014-11-19-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-11-19.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.stat.uchicago.edu/~lekheng/">Lek-Heng Lim</a>
    (U. of Chicago)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    19 Nov 2014
  </p>
  <div class="blurb"> 
  <p>One classical use of SVD is for computing principal angles and various
distances between two subspaces of the same dimension. There are a number of
applications that call for a notion of distance between two subspaces of
different dimensions. In iterative methods, this arises, for example, when one
examines the convergence of a sequence of Krylov subspaces of increasing
dimensions to a fixed subspace. In this talk, we will discuss various distances
for subspaces of different dimensions, including the containment gap due to
Tosio Kato.</p>

<p>This is joint work with Ke Ye of Chicago.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-17-cornell-scan.html">Tensor short course (IV)</a>
    <!-- <a href="/talks/2014-11-17-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cs.cornell.edu/cv/">Charlie Van Loan</a>
    (CS, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    17 Nov 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-17-cornell-cam.html">Bill Sears Club Seminar</a>
    <!-- <a href="/talks/2014-11-17-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_bill_sears_club_seminar_gennady_samorodnitsky_cornell_orie"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://legacy.orie.cornell.edu/gennady/">Gennady Samorodnitsky</a>
    (Cornell ORIE)<br/>
    
    Cornell Applied Math Colloquium,
    
    17 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Seminar named in honor of Bill Sears, the first director of CAM.</p>


  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-14-vt-am-colloq.html">A tensor-based dictionary approach to tomographic image reconstruction</a>
    <!-- <a href="/talks/2014-11-14-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/nov14.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.tufts.edu/~mkilme01/">Misha Kilmer</a>
    (Tufts University)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    14 Nov 2014
  </p>
  <div class="blurb"> 
  <p>In this talk, we consider how to represent and solve the problem of
reconstruction of x-ray tomographic images under the assumption that prior
information about the solution is available in the form of training images. The
main observation is that a collection of 2D (grayscale) training images can be
represented as a third-order tensor. From the training data, we wish to
construct a non-negative dictionary that contains prototype elements from the
images. Thus, we pose the dictionary learning phase as a non-negative tensor
factorization problem. Once the dictionary is available, the image
reconstruction phase consists of finding a sparse representation of the image
in the dictionary. Our numerical results indicate that we can get qualitatively
similar or better image reconstructions for sparser representations than using
a matrix-based equivalent. Additionally, we show that in the case of few
projections, our tensor-based approach gives images with superior structural
information than using total variation regularization.</p>


  </div>
</div>

<div class="series-manchester-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-14-manchester-nas.html">Max-plus approximation of the LU decomposition of a matrix</a>
    <!-- <a href="/talks/2014-11-14-manchester-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.maths.manchester.ac.uk/our-research/events/seminars/numerical-analysis-and-scientific-computing/max-plus-approximation-of-the-lu-decomposition-of-a-matrix.htm"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://personalpages.manchester.ac.uk/staff/James.hook/homepage.html">James Hook</a>
    (University of Manchester)<br/>
    
    Manchester Numerical Analysis Seminar,
    
    14 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Max-plus algebra has previously been used in NLA to approximate the size of the
eigenvalues (and singular values) of matrices and matrix polynomials. In this
talk I will describe a new max-plus method for approximating the size of the
entries in the LU factors of a matrix A.</p>

<p>This approximation can be used to predict the positions of the larger entries
in the LU factors of A and this information can be useful in constructing an
ILU preconditioner for A.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-14-cornell-cam.html">Adaptive Sampling for Stochastic Recursions</a>
    <!-- <a href="/talks/2014-11-14-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_raghu_pasupathy_purdue_-_adaptive_sampling_for_stochastic_recursions"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://web.ics.purdue.edu/~pasupath/">Raghu Pasupathy</a>
    (Purdue)<br/>
    
    Cornell Applied Math Colloquium,
    
    14 Nov 2014
  </p>
  <div class="blurb"> 
  <p>For roughly six decades since the seminal paper of Robbins and Monro (1951),
Stochastic Approximation has dominated the landscape of algorithms for solving
root finding and optimization problems with Monte Carlo observable functions.
Recently, however, inspired by the rise in parallel computing and advances in
nonlinear programming methods, there has been increasing interest in
alternative sampling-based frameworks. Such frameworks are convenient in that
they use an existing recursive method, e.g., quasi-Newton or trust-region
recursion, with embedded Monte Carlo estimators of objects appearing within the
recursion. In this talk, after reviewing some recent results on optimal
sampling rates, we consider the question of how to adaptively sample within
stochastic recursions. Specifically, we will demonstrate that a simple adaptive
scheme that has deep connections to proportional-width sequential confidence
intervals endows stochastic recursions with convergence rates that are
arbitrarily close to being optimal. Intriguingly, the adaptive sampling schemes
we advertise were independently discovered by Nocedal, et al., through
heuristic (but sound) arguments and numerical experimentation.</p>

<p>This is joint work with Fatemeh Hashemi (Virginia Tech), Soumyadip Ghosh (IBM
Research), and Peter Glynn (Stanford University).</p>


  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-13-stanford-la-opt.html">Wolfram Technologies in Education and Research</a>
    <!-- <a href="/talks/2014-11-13-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://icme.stanford.edu/events/cme-510-linear-algebra-and-optimization-seminar-5"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.wolfram.com">Paul Fish</a>
    (Wolfram Research, Inc)<br/>
    
    Stanford LA/OPT Seminar,
    
    13 Nov 2014
  </p>
  <div class="blurb"> 
  <p>The speaker will illustrate the capabilities in Mathematica 10 and
other Wolfram technologies that are applicable for teaching and
research on campus.</p>

<p>Attendees with no prior experience will learn how to get started
with Mathematica, thanks to improvements like free-form input and
the new Predictive Interface, which anticipates your next steps
and helps you quickly build up a series of calculations. Advanced
users report that they learn quite a few time saving tips and
tricks from the seminar. All attendees will receive an electronic
copy of the examples, which can be used as is or adapted to
individual projects.</p>

<p>No matter your level of technical expertise, you’ll find this
seminar very informative.</p>

  </div>
</div>

<div class="series-oxford-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-13-oxford-nas.html">Quadrature in infinite dimensions and applications in uncertainty quantification</a>
    <!-- <a href="/talks/2014-11-13-oxford-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.maths.ox.ac.uk/node/12962"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.maths.bath.ac.uk/~masrs/">Rob Scheichl</a>
    (University of Bath)<br/>
    
    Oxford Numerical Analysis Seminar,
    
    13 Nov 2014
  </p>
  <div class="blurb"> 
  <p>The coefficients in mathematical models of physical processes are often
impossible to determine fully or accurately, and are hence subject to
uncertainty. It is of great importance to quantify the uncertainty in the model
outputs based on the (uncertain) information that is available on the model
inputs. This invariably leads to very high dimensional quadrature problems
associated with the computation of statistics of quantities of interest, such
as the time it takes a pollutant plume in an uncertain subsurface flow problem
to reach the boundary of a safety region or the buckling load of an airplane
wing. Higher order methods, such as stochastic Galerkin or polynomial chaos
methods, suffer from the curse of dimensionality and when the physical models
themselves are complex and computationally costly, they become prohibitively
expensive in higher dimensions. Instead, some of the most promising approaches
to quantify uncertainties in continuum models are based on Monte Carlo sampling
and the “multigrid philosophy”. Multilevel Monte Carlo (MLMC) Methods have been
introduced recently and successfully applied to many model problems, producing
significant gains. In this talk I want to recall the classical MLMC method and
then show how the gains can be improved further (significantly) by using
quasi-Monte Carlo (QMC) sampling rules. More importantly the dimension
independence and the improved gains can be justified rigorously for an
important model problem in subsurface flow. To achieve uniform bounds,
independent of the dimension, it is necessary to work in infinite dimensions
and to study quadrature in sequence spaces. I will present the elements of this
new theory for the case of lognormal random coefficients in a diffusion problem
and support the theory with numerical experiments.</p>

  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-12-ucb-lapack.html">Generating Polynomials and Symmetric Tensor Decompositions</a>
    <!-- <a href="/talks/2014-11-12-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-11-12.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.ucsd.edu/~njw/">Jiawang Nie</a>
    (UCSD)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    12 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Symmetric tensors are multi-indexed arrays whose entries are invariant with
respect to permutations of multi-indices. Generating polynomials are linear
relations of recursive patterns about tensor entries. A set of all generating
polynomials can be represented by a matrix, which is called a generating
matrix. Generally, a symmetric tensor decomposition can be uniquely determined
by a generating matrix. We characterize the sets of such generating matrices
and investigate their properties (e.g., the existence, dimensions,
nondefectiveness). Using these properties, we propose computational methods for
symmetric tensor decompositions. Extensive examples are shown to demonstrate
their efficiency.</p>


  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-11-stanford-la-opt.html">Recent developments in optimization solvers</a>
    <!-- <a href="/talks/2014-11-11-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    Erling Andersen
    
    (CEO, MOSEK)<br/>
    
    Stanford LA/OPT Seminar,
    
    11 Nov 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-10-ucb-lapack.html">Automatic Code Generation for Performance Libraries</a>
    <!-- <a href="/talks/2014-11-10-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    Greg Henry
    
    (Intel)<br/>
    
    10 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Intel® Math Kernel Library (Intel® MKL) is well known across many scientific
domains disciplines as the premiere HPC library. With the advent of multi-core
and heterogeneous computations (computations shared across different hardware
configurations), algorithm complexity continues to grow with each processor
generation. One of the most time consuming tasks in library development is the
incorporation of a new algorithm when there are alternatives that can perform
better for certain inputs. We present here a method we use for automating some
of the decision processes for merging different algorithms to create optimal
hybrid solutions as well as techniques for tuning parameters such as the ideal
number of threads. We compare against the latest techniques in machine learning
and use some of these approaches to create a novel technique for automatically
optimizing the algorithm and gaining maximum parallel efficiency. This goes
beyond auto-tuning- we describe methods that enable the auto-generation of code
that is ready to use. Our goal is to auto-generate software that runs quickly
enough to allow finding the best choice at run-time.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-10-cornell-scan.html">Tensor short course (III)</a>
    <!-- <a href="/talks/2014-11-10-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cs.cornell.edu/cv/">Charlie Van Loan</a>
    (CS, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    10 Nov 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-07-vt-am-colloq.html">On polynomial filtering in implicitly restarted Arnoldi type algorithms</a>
    <!-- <a href="/talks/2014-11-07-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/nov07.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://web.math.pmf.unizg.hr/~drmac/">Zlatko Drmac</a>
    (Univ of Zagreb, Croatia)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    07 Nov 2014
  </p>
  <div class="blurb"> 
  <p>We explore the theoretical framework of the implicitly restarted Arnoldi and
the Krylov-Schur algorithm for computing only a small number of matrix
eigenpairs that satisfy some property (e.g. all eigenvalues contained in a
given domain, or certain number of eigenvalues closest to the origin or to the
imaginary axis etc.). In particular, we focus on the theoretical possibility
for implicit restarting of the Krylov-Schur algorithm with arbitrary polynomial
filter – a functionality lacking in the original algorithm. Our results reveal
a very interesting latent connection between implicit restarting with arbitrary
polynomial filter and the partial pole placement (eigenvalue assignment)
problem.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-07-cornell-cam.html">Spectral multidomain-based modeling of small-scale environmental flow processes</a>
    <!-- <a href="/talks/2014-11-07-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_peter_diamessis_cornell_cee_-_spectral_multidomain-based_modeling_of_small-scale_environmental_flow_processes"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cee.cornell.edu/people/profile.cfm?netid=pjd38">Peter Diamessis</a>
    (Cornell CEE)<br/>
    
    Cornell Applied Math Colloquium,
    
    07 Nov 2014
  </p>
  <div class="blurb"> 
  <p>This presentation focuses on the numerical methods developed by our research
group for the simulation of incompressible stratified flows. In addition, the
application of these methods to the investigation of stratified flow processes
beneath the surfaces of the ocean and lakes, namely the interplay between
internal gravity waves and turbulence, will be discussed. Following an
introduction to the environmental importance of such fascinating phenomena, I
will elaborate on the suitability of element-based high-accuracy techniques for
their study. An introduction to the fundamentals of these techniques will then
be given. Example results from three select studies, relying on a spectral
multidomain penalty method (SMPM)-based flow solver, will be shown. Emphasis
will be placed on physical insights gained and the logistics involved with
running large simulations and managing and analyzing the large datasets they
produce. The challenges involved in extending the current version of our
SMPM-solver to accommodate more complex geometries and boundary conditions will
finally be discussed. The emphasis of this final discussion will be on the
design of an efficient parallel solver for the pressure Poisson equation to be
used for the study of highly non-hydrostatic phenomena in high-aspect ratio
domains.</p>


  </div>
</div>

<div class="series-oxford-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-06-oxford-nas.html">Tomographic problems as linear algebra</a>
    <!-- <a href="/talks/2014-11-06-oxford-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.maths.ox.ac.uk/node/12961"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.maths.manchester.ac.uk/~bl/">Bill Lionheart</a>
    (Manchester University)<br/>
    
    Oxford Numerical Analysis Seminar,
    
    06 Nov 2014
  </p>
  <div class="blurb"> 
  <p>For many tomographic imaging problems there are explicit inversion formulas,
and depending on the completeness of the data these are unstable to differing
degrees. Increasingly we are solving tomographic problems as though they were
any other linear inverse problem using numerical linear algebra. I will
illustrate the use of numerical singular value decomposition to explore the
(in)stability for various problems. I will also show how standard techniques
from numerical linear algebra, such as conjugate gradient least squares, can be
employed with systematic regularization compared with the ad hoc use of slowly
convergent iterative methods more traditionally used in computed tomography. I
will mainly illustrate the talk with examples from three dimensional x-ray
tomography but I will also touch on tensor tomography problems.</p>

  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-05-ucb-lapack.html">Improved Column-Based Matrix Reconstruction</a>
    <!-- <a href="/talks/2014-11-05-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-11-05.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    Chris Melgaard
    
    (UC Berkeley)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    05 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Column-based matrix reconstruction, or the CX decomposition, has become a
popular tool in large-scale data analysis for constructing low-rank matrix
approximations built using the features (or columns) of the data. In this work,
we present a modiﬁed deterministic algorithm for column selection, based on the
seminal work of Boutsidis, Drineas and Magdon-Ismail. Our modiﬁed algorithm
enjoys improved computational complexity, less memory usage and stronger error
bounds. We also provide a randomized version for further computational
efficiency. Our algorithms offer stronger controls on the spectral and
Frobenius norm errors. Additionally, we provide novel rank revealing lower
bounds on the individual singular values in the CX decomposition. For matrices
with decaying singular values (the typical case with real-world data), our
bounds surprisingly suggest that the CX decomposition is capable of accurately
retaining the leading singular values almost at the same accuracy as the
truncated SVD. Using synthetic and real data matrices, we report numerical
tests to reaffirm the efficiency and accuracy of our algorithms.</p>


  </div>
</div>

<div class="series-ncsu-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-04-ncsu-nas.html">Monte Carlo Synthetic Acceleration Algorithms for Linear Systems</a>
    <!-- <a href="/talks/2014-11-04-ncsu-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2491"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://cnerg.github.io/people/slattery.html">Stuart Slattery</a>
    (Oak Ridge National Laboratory)<br/>
    
    NCSU Numerical Analysis Seminar,
    
    04 Nov 2014
  </p>
  <div class="blurb"> 
  <p>Monte Carlo Synthetic Acceleration (MCSA) algorithms for linear systems are
currently being researched as a potential scalable and resilient linear solver
for exascale computing systems. Our team is focusing on several aspects of
these algorithms including basic theory, preconditioning, parallelism,
performance modeling, and resiliency. In this talk I will provide an
introduction to solving linear systems with Monte Carlo initially developed by
Von Neumann and Ulam followed by an outline of the MCSA scheme. I will then
discuss some of our recent algorithmic developments aimed at enabling both
better iterative performance as well as hybrid parallelism. I will then present
a domain decomposition scheme we have developed for the algorithm based on
parallel Monte Carlo particle transport schemes. I will end the talk by giving
results for both a linearized form of the transient radiation diffusion
equation as well as a SPn discretization of the neutron transport equation for
light water reactor problems.</p>

  </div>
</div>

<div class="series-mit-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-03-mit-amc.html">Fast spectral function approximation on complex geometries: redundancy and ill-conditioning are sometimes helpful</a>
    <!-- <a href="/talks/2014-11-03-mit-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www-math.mit.edu/amc/fall14/huybrechs.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://people.cs.kuleuven.be/~daan.huybrechs/">Daan Huybrechs</a>
    (KU Leuven)<br/>
    
    MIT Applied Math Colloquium,
    
    03 Nov 2014
  </p>
  <div class="blurb"> 
  <p>It is challenging to construct a basis for a function space that is associated
with a domain with complicated geometry, at least when one aims for spectral
accuracy and fast transforms. A basis should be complete but not redundant, and
this combination of properties is quite restrictive. Things become considerably
easier by relaxing the latter property: it is nearly trivial to find complete
but redundant sets, or frames, for pretty much any domain. This includes exotic
ones like fractal sets. Unfortunately, redundancy implies non-uniqueness and
this in turn may lead to ill-conditioning of several common operations.</p>

<p>In this talk we explore simple frames based on Fourier series for the
approximation of functions on funny domains. These are very much related to
Fourier extensions or Fourier continuations, but they are genuinely
higher-dimensional. A number of results in this area seemingly defy common
intuition about Fourier series. Perhaps most surprising is the observation that
the approximation problem is unstable in theory, but numerically stable in
practice. The stability is due, in fact, to extreme ill-conditioning.</p>

<p>We illustrate the results with a toolbox implemented in Julia. Being based on
Fourier series, most operations can be carried out very efficiently using the
FFT, in spite of the lack of periodicity or any sort of regularity of the
domain under consideration.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-11-03-cornell-scan.html">Tensor short course (II)</a>
    <!-- <a href="/talks/2014-11-03-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/Tensor2.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cs.cornell.edu/cv/">Charlie Van Loan</a>
    (CS, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    03 Nov 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-31-cornell-cam.html">Optimal Learning for Molecular Discovery</a>
    <!-- <a href="/talks/2014-10-31-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_peter_frazier_cornell_orie_-_optimal_learning_for_molecular_discovery"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://people.orie.cornell.edu/pfrazier/">Peter Frazier</a>
    (Cornell ORIE)<br/>
    
    Cornell Applied Math Colloquium,
    
    31 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Scientists use laboratory experiments to search for molecules with desirable
properties, e.g., that make efficient solar cells; or that cure cancer. The
success of such a search hinges on making good decisions about which
experiments to perform. We show how machine learning and value of information
analysis — together in an optimal learning framework — can be used to choose
good experiments, and to reach experimental goals reliably with fewer
experiments.</p>

<p>We first describe how these mathematical methods were used to successfully find
minimal peptide substrates for a pair of protein-modifying enzymes. These novel
peptides support reversible protein tagging, with application to medicine and
biochemical sensors. We then review two other applications: growing carbon
nanotubes, and finding peptides that bind to inorganic materials.</p>


  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-30-vt-am-colloq.html">Regularization model for incompressible flow simulation</a>
    <!-- <a href="/talks/2014-10-30-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/oct30.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.clemson.edu/~rebholz/">Leo Rebholz</a>
    (Clemson)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    30 Oct 2014
  </p>
  <div class="blurb"> 
  <p>This talk presents a high level overview of regularization models for fluid
flow simulation. After discussing the analytic and computational difficulties
of the Navier-Stokes equations, we introduce regularization models as an
alternative to the NSE that are both well-posed and more easily computable.
Improving regularization models with the use of approximate deconvolution is
then discussed, followed by important details regarding numerical
implementation. Results of several numerical experiments will be given to
illustrate the usefulness of these models.</p>

  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-30-stanford-la-opt.html">Algorithmic Reslience for Linear Algebra</a>
    <!-- <a href="/talks/2014-10-30-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://greg.bronevetsky.com/">Greg Bronevetsky</a>
    (Lawrence Livermore National Laboratory)<br/>
    
    Stanford LA/OPT Seminar,
    
    30 Oct 2014
  </p>
  <div class="blurb"> 
  <p>As High-Performance Computing systems approach Exascale the feature sizes of
their circuits will shrink, while their overall size will grow, all at a fixed
power budget.  As transistors are packed more tightly and hold less charge,
they are expected to grow more vulnerable to a range of faults that corrupt the
computations of the logic circuits built from them.  These faults manifest
themselves as errors in hardware computations, which can propagate to cause
applications to crash, or worse—to silently return incorrect results.  While
it is possible to make hardware more reliable in a way that is transparent to
application software, such techniques are expensive, requiring all computations
to be repeated multiple times, or circuits to be built from more reliable
transistors.  This motivates the development of algorithms that are naturally
resilient to hardware errors.</p>

<p>This talk will survey work on algorithmic resilience techniques for linear
algebra computations.  It will cover techniques for basic operations such as
matrix multiplication and factorization, as well as iterative linear solvers.
Finally, I will point out the wide range of algorithms for which no checkers
are known, and various open research opportunities in the field of resilient
algorithms, resilience-aware programming models, and approximate computing in
general.</p>


  </div>
</div>

<div class="series-oxford-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-30-oxford-nas.html">Polynomial hulls, low rank perturbations and multicentric calculus</a>
    <!-- <a href="/talks/2014-10-30-oxford-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.maths.ox.ac.uk/node/12959"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://math.aalto.fi/en/people/olavi.nevanlinna">Olavi Nevanlinna</a>
    (Aalto University)<br/>
    
    Oxford Numerical Analysis Seminar,
    
    30 Oct 2014
  </p>
  <div class="blurb"> 
  <p>We outline a path from polynomial numerical hulls to multicentric calculus for evaluating f(A). Consider
<script type="math/tex">
  Vp(A)=z∈C:|p(z)|≤kp(A)k
</script>
where p is a polynomial and A a bounded linear operator (or matrix). Intersecting these sets over polynomials of degree 1 gives the closure of the numerical range, while intersecting over all polynomials gives the spectrum of A, with possible holes filled in.
Outside any set Vp(A) one can write the resolvent down explicitly and this leads to multicentric holomorphic functional calculus.
The spectrum, pseudospectrum or the polynomial numerical hulls can move rapidly in low rank perturbations. However, this happens in a very controlled way and when measured correctly one gets an identity which shows e.g. the following: if you have a low-rank homotopy between self-adjoint and quasinilpotent, then the identity forces the nonnormality to increase in exact compensation with the spectrum shrinking.
In this talk we shall mention how the multicentric calculus leads to a nontrivial extension of von Neumann theorem
<script type="math/tex">
  kf(A)k \leq sup |z| \leq 1 kf(z)k
</script>
where A is a contraction in a Hilbert space, and conclude with some new results on (nonholomorphic) functional calculus for operators for which p(A) is normal at a nontrivial polynomial p. Notice that this is always true for matrices.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-29-ucb-lapack.html">An Efficient Algorithm for Spectral Graph Sparsification</a>
    <!-- <a href="/talks/2014-10-29-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-10-29.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://math.berkeley.edu/~dga/">Dave Anderson</a>
    (UC Berkeley)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    29 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Spectral graph sparsification has emerged as a useful tool in the analysis of
large-scale networks by reducing the overall number of edges, while maintaining
a comparable graph Laplacian matrix.  This talk will provide a brief
introduction to graph sparsification and its applications.  Then a novel graph
sparsification algorithm will be presented for the construction of a new type
of spectral sparsifier, the unweighted spectral sparsifier.</p>

<p>The graph sparsification algorithm will be derived using a purely linear
algebra result: a deterministic algorithm for finding a well-conditioned
submatrix by selecting columns from a row orthonormal matrix.  For any graph,
this algorithm will find a subgraph with a comparable Laplacian.  While current
methods accomplish this by reassigning edge weights, this algorithm will find a
sparsifier and will leave edge weights intact.</p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-29-temple-am.html">Flexible Krylov Solvers for Shifted Systems</a>
    <!-- <a href="/talks/2014-10-29-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.Saibaba.29Oct14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.eecs.tufts.edu/~arvindks/">Arvind K. Saibaba</a>
    (Tufts University)<br/>
    
    Temple Applied Math Seminar,
    
    29 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-ncsu-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-28-ncsu-amc.html">Global well-posedness for a relaxed Landau equation</a>
    <!-- <a href="/talks/2014-10-28-ncsu-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2548"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://home.gwu.edu/~gualdani/">Maria Pia Gualdani</a>
    (George Washington University)<br/>
    
    NCSU Applied Math Seminar,
    
    28 Oct 2014
  </p>
  <div class="blurb"> 
  <p>We present global well-posedness results for a relaxed version of the Landau
equation with Coulomb potential. Despite lack of a comparison principle for the
equation, the proof of existence relies on barrier arguments and parabolic
regularity theory. The Landau equation arises in kinetic theory of plasma
physics. It was derived by Landau and serves as a formal approximation to the
Boltzmann equation when grazing collisions are predominant.</p>

  </div>
</div>

<div class="series-mit-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-27-mit-amc.html">Implicit Solvers for Incompressible Flow Problems</a>
    <!-- <a href="/talks/2014-10-27-mit-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www-math.mit.edu/amc/fall14/silvester.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.maths.manchester.ac.uk/~djs/">David Silvester</a>
    (University of Manchester)<br/>
    
    MIT Applied Math Colloquium,
    
    27 Oct 2014
  </p>
  <div class="blurb"> 
  <p>This survey talk reviews some recent developments in the design of robust
solution methods for the Navier-Stokes equations modelling incompressible fluid
flow.  There are two building blocks in our solution strategy.  First, an
implicit time integrator that uses a stabilized trapezoid rule with an explicit
Adams-Bashforth method for error control, and second, a robust Krylov subspace
solver for the spatially discretized system.  Numerical experiments are
presented that illustrate the effectiveness of our generic approach.  It is
further shown that the basic solution strategy can be readily extended to more
complicated models, including unsteady flow problems with coupled physics and
steady flow problems that are stochastic in the sense that they have uncertain
input data.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-27-cornell-scan.html">Tensor short course (I) : Connecting to Matrix Computations.</a>
    <!-- <a href="/talks/2014-10-27-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/Tensor1.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cs.cornell.edu/cv/">Charlie Van Loan</a>
    (CS, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    27 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-24-cornell-cam.html">Computing Global Invariant Manifolds: Techniques and Applications</a>
    <!-- <a href="/talks/2014-10-24-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_hinke_osinga_univ_of_auckland_-_computing_global_invariant_manifolds_techniques_and_applications"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://www.math.auckland.ac.nz/~hinke/">Hinke Osinga</a>
    (Univ. of Auckland)<br/>
    
    Cornell Applied Math Colloquium,
    
    24 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Global invariant manifolds play an important role in organizing the behavior of
a dynamical system. Together with equilibria and periodic orbits, they form the
so-called skeleton of the dynamics and offer geometric insight into how
observed behavior arises. In most cases, it is impossible to find invariant
manifolds explicitly and numerical methods must be used to find accurate
approximations. Developing such computational techniques is a challenge on its
own and, to this date, the focus has primarily been on computing
two-dimensional manifolds. Nevertheless, these computational efforts offer new
insights that go far beyond a confirmation of the known theory. Furthermore,
global invariant manifolds in dynamical systems theory not only explain
asymptotic behavior, but more recent developments show that they are equally
useful for explaining short-term transient dynamics. We present an overview of
these more recent developments, in terms of novel computational methods, as
well as applications that have stimulated recent advances in the field and
highlighted the need for new mathematical theory.</p>


  </div>
</div>

<div class="series-oxford-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-23-oxford-nas.html">Stabilised finite element methods for non symmetric, non coercive and ill-posed problems</a>
    <!-- <a href="/talks/2014-10-23-oxford-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.maths.ox.ac.uk/node/12957"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://iris.ucl.ac.uk/iris/browse/profile?upi=ENBUR31">Erik Burman</a>
    (UCL)<br/>
    
    Oxford Numerical Analysis Seminar,
    
    23 Oct 2014
  </p>
  <div class="blurb"> 
  <p>In numerical analysis the design and analysis of computational methods is often
based on, and closely linked to, a well-posedness result for the underlying
continuous problem. In particular the continuous dependence of the continuous
model is inherited by the computational method when such an approach is used.
In this talk our aim is to design a stabilised finite element method that can
exploit continuous dependence of the underlying physical problem without making
use of a standard well-posedness result such as Lax-Milgram’s Lemma or The
Babuska-Brezzi theorem. This is of particular interest for inverse problems or
data assimilation problems which may not enter the framework of the above
mentioned well-posedness results, but can nevertheless satisfy some weak
continuous dependence properties. First we will discuss non-coercive elliptic
and hyperbolic equations where the discrete problem can be ill-posed even for
well posed continuous problems and then we will discuss the linear elliptic
Cauchy problem as an example of an ill-posed problem where there are continuous
dependence results available that are suitable for the framework that we
propose.</p>

  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-22-ucb-lapack.html">A Projected Preconditioned Conjugate Gradient algorithm for computing a large invariant subspace of a Hermitian matrix</a>
    <!-- <a href="/talks/2014-10-22-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-10-15.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://evecharynski.com/">Eugene Vecharynski</a>
    (LBNL)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    22 Oct 2014
  </p>
  <div class="blurb"> 
  <p>The Rayleigh-Ritz (RR) procedure constitutes one of the major steps in
eigenvalue computations. Most of the standard eigenvalue solvers employ this
mechanism at each iteration to extract approximate eigenpairs. In practice, the
RR calculations amount to solving a projected dense eigenvalue problem. The
size of this projected problem is typically proportional to the number of
targeted eigenpairs.</p>

<p>If only a few eigenpairs are sought, then the cost of the RR procedure is
negligibly low and the associated computations have no significant effect on
the overall performance of an eigenvalue solver. However, if the number of
targeted eigenpairs is large, e.g., on the order of thousands or more, then the
RR cost may become dominant and may noticeably affect the solution time. The
relative high cost comes from the cubic scaling of the complexity of the dense
eigenvalue problem,  as well as limited scalability of the current generation
of dense eigensolvers  in the distributed memory environment.  </p>

<p>In this talk, I will address the question of avoiding the frequent RR
computations for Hermitian  eigenvalue problems where a large number of extreme
eigenpairs is wanted.  I will describe a new approach that is based on a
preconditioned gradient-type scheme that does not rely on the RR  procedure at
each iteration. Several numerical results, where the proposed technique is
applied to realistic problems arising in electronic structure calculations,
will be presented.</p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-22-temple-am.html">Refraction Problems in Geometric Optics</a>
    <!-- <a href="/talks/2014-10-22-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.Gutierrez.22Oct14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://math.temple.edu/~gutierre/">Cristian E. Gutierrez</a>
    (Temple University)<br/>
    
    Temple Applied Math Seminar,
    
    22 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-ncsu-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-22-ncsu-nas.html">A high-order discontinuous Galerkin scheme for entropy-based moment closures of linear kinetic equations</a>
    <!-- <a href="/talks/2014-10-22-ncsu-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2709"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.mathcces.rwth-aachen.de/5people/alldredge/start">Graham Alldredge</a>
    (Aachen)<br/>
    
    NCSU Numerical Analysis Seminar,
    
    22 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-20-cornell-scan.html">Interacting slow manifolds in multiple-time-scale systems</a>
    <!-- <a href="/talks/2014-10-20-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-krauskopf-osinga-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://www.math.auckland.ac.nz/~berndk/">Bernd Krauskopf and Hinke Osinga</a>
    (Math, U. of Auckland)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    20 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Dynamics that evolves on at least two different time scales occurs in many applications; examples are pulsing dynamics, chemical reaction dynamics and spiking or bursting of neurons. From the mathematical point of view, this type of dynamics is organised in the phase space of relevant ODE models by special surfaces, called attracting and repelling slow manifolds. We show how slow manifolds can be computed and visualised via boundary value problem formulations. This allows us to determine how they interact and intersect in what are known as canard orbits, which determine the pattern of pulses or spikes that are observed.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-17-vt-am-colloq.html">The Phase Field Crystal Model: A Continuum Framework for Studying Phase Transformations on Atomic Length and Diffusive Time Scales</a>
    <!-- <a href="/talks/2014-10-17-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/oct17.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.utk.edu/~swise/Site/Welcome.html">Steven Michael Wise</a>
    (Univ of TN at Knoxville)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    17 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Crystalline materials contain atomic-scale imperfections in the form of defects
– such as vacancies, grain boundaries, and dislocations – and controlling, or
at least predicting, the formation and evolution of such imperfections during
phase transformation is a major challenge. The phase field crystal (PFC)
methodology has emerged as a important, increasingly-preferred modeling
framework for studying materials with atomic-scale structures on diffusive time
scales. In contrast to molecular dynamics models, the fast atomic vibrational
time-scale phenomena are averaged out, in essence, but the atomic spatial
resolution is preserved. In this talk, I will describe some analysis (e.g.,
existence and uniqueness), approximation, and fast computation of solutions to
PFC and PFC-type equations, a family of highly nonlinear hyperbolic-parabolic
PDE and integro-PDE. I will also discuss a new PFC framework for
multi-spatial-scale modeling based on the recent method of amplitude
expansions. This presentation will be accessible to graduate students.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-17-cornell-cam.html">What is all the fuss concerning Common Core Math Standards - and why should you care?</a>
    <!-- <a href="/talks/2014-10-17-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_grant_wiggins_authentic_education_-_what_is_all_the_fuss_concerning_common_core_math_standards_-_and_why_should_you_care"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.authenticeducation.org/whoweare/grant.lasso">Grant Wiggins</a>
    (Authentic Education)<br/>
    
    Cornell Applied Math Colloquium,
    
    17 Oct 2014
  </p>
  <div class="blurb"> 
  <p>As we know, the new national standards for math in K-12 education have gone
from being completely ho-hum and ignored to becoming a hot-button political
issue. What should we make of the controversy? What role, if any, should
college faculty play in terms of the Standards? Noted educational researcher,
consultant, and reformer Grant Wiggins will try to shed more light than heat on
this important topic.</p>

  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-16-stanford-la-opt.html">Design Optimization and the Consider-Then-Choose Behavioral Model</a>
    <!-- <a href="/talks/2014-10-16-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://sites.google.com/site/wrossmorrow/">W. Ross Morrow (with Minhua Long and Erin MacDonald)</a>
    (Iowa State and Stanford MAE)<br/>
    
    Stanford LA/OPT Seminar,
    
    16 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Recent research in engineering design and operations adopts discrete
choice models to maximize profits (or revenues).  Conventional discrete
choice models are mainly predictive, instead of descriptive, in that
they only intend to predict choices rather than describe the processes
underlying choice.  The consider-then-choose model describes a two-stage
decision-making process in which consumers first eliminate a large
number of product alternatives with heuristic screening rules, then
perform careful tradeoff evaluation over the remaining alternatives.</p>

<p>Consideration, also called choice set formation, is an empirically
validated choice behavior that has been shown to greatly improve model
quality.  From the perspective of firm strategy, modeling consideration
introduces discontinuous choice probabilities to optimal design problems,
as changes in product features or prices can change individuals’ choice
sets.  We introduce consider-then-choose models, review research
suggesting their importance for use in design, and compare several
treatments of the discontinuous optimal design problem.  We use a
stylized new vehicle portfolio design example throughout.</p>


  </div>
</div>

<div class="series-oxford-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-16-oxford-nas.html">Adjoint-based optimisation for flow analysis and flow control</a>
    <!-- <a href="/talks/2014-10-16-oxford-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.maths.ox.ac.uk/node/12956"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.imperial.ac.uk/people/peter.schmid">Peter Schmid</a>
    (Imperial College London)<br/>
    
    Oxford Numerical Analysis Seminar,
    
    16 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Gradient-based optimisation techniques have become a common tool in the
analysis of fluid systems. They have been applied to replace and extend
large-scale matrix decompositions to compute optimal amplification and optimal
frequency responses in unstable and stable flows. We will show how to
efficiently extract linearised and adjoint information directly from nonlinear
simulation codes and how to use this information for determining common flow
characteristics. We also extend this framework to deal with the optimisation of
less common norms. Examples from aero-acoustics and mixing will be presented.</p>

  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-15-ucb-lapack.html">How practical is fast matrix multiplication?</a>
    <!-- <a href="/talks/2014-10-15-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-10-15.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.sandia.gov/~gmballa/">Grey Ballard</a>
    (Sandia National Lab)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    15 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Determining the exponent of matrix multiplication has been an exciting
theoretical pursuit for many years, and there continue to be improvements on
the best lower and upper bounds.  While “fast” algorithms for matrix
multiplication perform O(n^w) floating point operations in multiplying n-by-n
matrices with w&lt;3, they are seldom used in practice.  The original fast
algorithm, discovered by Strassen, is known to be practical (i.e.,
outperforming the best implementation of the classical O(n^3) algorithm on
reasonably sized matrices), but most of the other advances in the field of fast
matrix multiplication have focused more on theoretical questions rather than
practical ones.  I’ll talk about how advances in communication-avoiding
algorithms have created some optimism for the practicality of fast algorithms,
show some promising practical results in parallelizing Strassen’s algorithm,
and discuss the prospects of other fast and practical matrix multiplication
algorithms.  In particular, I’ll discuss recent results in using computer-aided
search to find many different fast algorithms and then benchmarking their
performance on both sequential and shared-memory parallel architectures.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-10-vt-am-colloq.html">A parallel iterative approach for computing and updating a sparse approximate matrix factorization</a>
    <!-- <a href="/talks/2014-10-10-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/oct10.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cc.gatech.edu/~echow/index.html">Edmond Chow</a>
    (Georgia Tech)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    10 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Matrix factorizations are ubiquitous and fundamental for solving problems in
science, engineering, and data analysis. In this talk, we consider a new
iterative approach for approximately computing certain sparse matrix
factorizations. The approach is designed to be highly parallel, with all
entries in the factorization being simultaneously updated by all available
parallel resources. As an iterative approach, the method can be naturally used
to update a matrix factorization in time-dependent simulations or streaming
data problems. This talk will focus on computing incomplete factorizations and
sparse approximate inverses, which are commonly used as preconditioners for
solving large, sparse linear systems.</p>

  </div>
</div>

<div class="series-manchester-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-10-manchester-nas.html">Multicentric Calculus: A New Look at f(A)</a>
    <!-- <a href="/talks/2014-10-10-manchester-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.maths.manchester.ac.uk/our-research/events/seminars/numerical-analysis-and-scientific-computing/multicentric-calculus-a-new-look-at-fa.htm"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://math.aalto.fi/en/people/olavi.nevanlinna">Olavi Nevanlinna</a>
    (Aalto University)<br/>
    
    Manchester Numerical Analysis Seminar,
    
    10 Oct 2014
  </p>
  <div class="blurb"> 
  <p>We outline a path from polynomial numerical hulls to multicentric calculus for
evaluating $f(A)$. Consider </p>

<script type="math/tex; mode=display"> V_p(A) = \{ z \in \mathbb{C} : |p(z)| \leq \|p(A)\| \} </script>

<p>where $p$ is a polynomial and $A$ a bounded linear operator (or
matrix). Intersecting these sets over polynomials of degree 1 gives the closure
of the numerical range, while intersecting over all polynomials gives the
spectrum of A, with possible holes filled in [1].</p>

<p>Outside any set $V_p(A)$ one can write the resolvent down explicitly and this
leads to multicentric holomorphic functional calculus [3], [4].</p>

<p>The spectrum, pseudospectrum or the polynomial numerical hulls can move rapidly
in low rank perturbations. However, this happens in a very controlled way and
when measured correctly one gets an identity which shows e.g. the following: if
you have a low-rank homotopy between self-adjoint and quasinilpotent, then the
identity forces the nonnormality to increase in exact compensation with the
spectrum shrinking [2].</p>

<p>In this talk we shall mention how the multicentric calculus leads to a
nontrivial extension of von Neumann theorem </p>

<script type="math/tex; mode=display"> \|f(A)\| \leq \sup_{|z| \leq 1} \|f(z)\| </script>

<p>where $A$ is a contraction in a
Hilbert space, [5], and conclude with some new results on (nonholomorphic)
functional calculus for operators for which $p(A)$ is (similar to) normal at a
nontrivial polynomial $p$. The results are new even for matrices.</p>

<h2 id="references">References</h2>

<ol>
  <li>Convergence of Iterations for Linear Equations, Birkhäuser, 1993</li>
  <li>Meromorphic Functions and Linear Algebra, Fields Institute Monographs, 18, AMS 2003</li>
  <li>Computing the Spectrum and Representing the Resolvent, Numer. Funct. Anal. Optimiz. Volume 30, Issue 9 and 10 (2009) 1025 - 1047</li>
  <li>Multicentric Holomorphic Calculus, Computational Methods and Function Theory, June 2012, Volume 12, Issue 1, pp 45-65</li>
  <li>Lemniscates and K-spectral sets, J. Funct. Anal. 262(2012), 1728-1741.</li>
</ol>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-10-cornell-cam.html">A Correlated Site Percolation Model of a Viscoplastic Fluid</a>
    <!-- <a href="/talks/2014-10-10-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_raazesh_sainudiin_canterbury_"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.canterbury.ac.nz/~r.sainudiin/">Raazesh Sainudiin</a>
    (Canterbury)<br/>
    
    Cornell Applied Math Colloquium,
    
    10 Oct 2014
  </p>
  <div class="blurb"> 
  <p>We present a Gibbs random field model for the microscopic interactions in a
viscoplastic fluid. The energy function is derived from the Gibbs potential in
terms of the external stress and internal energy. The resulting Gibbs
distribution, over a configuration space of microscopic interactions, can mimic
experimentally observed macroscopic behavioral phenomena that depend on the
externally applied stress. A simulation algorithm that can be used to
approximate samples from the Gibbs distribution is given and it is used to gain
several insights about the model. The model has two parameters for the internal
energy of the material in the absence of external stress and a third parameter
for a constant externally applied stress. An approximating differential
equation for the expected proportion of the material in the solid phase is
derived by a spatio-temporal rescaling of the toroidal square lattice upon
which the Gibbs random field model is defined. The asymptotic dynamics of this
tri-parametric family of differential equation matches with those of the
rescaled simulations from the Gibbs field model and can account for the
macroscopic behaviors, including solid-fluid phase transitions in the presence
of constant as well as varying external stress and the associated hysteresis.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-08-ucb-lapack.html">Enlarged Krylov subspace methods for reducing communication</a>
    <!-- <a href="/talks/2014-10-08-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-10-08.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://who.rocq.inria.fr/Laura.Grigori/">Laura Grigori</a>
    (INRIA Paris)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    08 Oct 2013
  </p>
  <div class="blurb"> 
  <p>In this talk we discuss iterative methods for solving sparse linear systems of
equations of the form Ax=b.  We introduce a new approach for reducing
communication in Krylov subspace methods that consists of enlarging the Krylov
subspace by a maximum of t vectors per iteration, based on the domain
decomposition of the graph of A. The obtained enlarged Krylov subspace is a
superset of the classic Krylov subspace. Thus it is possible to search for the
solution of the system Ax=b in the enlarged Krylov subspace instead of the
classic one.  We show in this talk that the enlarged Krylov projection subspace
methods lead to faster convergence in terms of iterations and parallelizable
algorithms with less communication, with respect to Krylov methods.</p>


  </div>
</div>

<div class="series-ncsu-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-07-ncsu-nas.html">Approximate Separability of Greens Function for Helmholtz Equation in the High Frequency Limit</a>
    <!-- <a href="/talks/2014-10-07-ncsu-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2419"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.uci.edu/~zhao">Hongkai Zhao</a>
    (UC Irvine)<br/>
    
    NCSU Numerical Analysis Seminar,
    
    07 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Approximate separable representations of Greens functions for differential
operators is a basic and important question in the analysis of differential
equations, the development of efficient numerical algorithms and imaging. Being
able to approximate a Greens function as a sum with few separable terms is
equivalent to low rank properties of corresponding numerical solution
operators. This will allow for matrix compression and fast solution techniques.
Greens functions for coercive elliptic differential operators have been shown
to be highly separable and the resulting low rank property for discretized
system was explored to develop efficient numerical algorithms. However, the
case of Helmholtz equation in the high frequency limit is more challenging both
mathematically and numerically. We introduce new tools based on the study of
relations between two Greens functions with different source points and a tight
dimension estimate for the best linear subspace approximating a set of almost
orthogonal vectors to prove new lower bounds for the number of terms in the
representation for the Greens function for Helmholtz operator in the high
frequency limit. Upper bounds are also derived. We give explicit sharp
estimates for cases that are common in practice and present numerical examples.
This is a joint work with Bjorn Engquist.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-06-cornell-scan.html">Inverting for maritime environments using empirical eigenfunction bases from radar imagery.</a>
    <!-- <a href="/talks/2014-10-06-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-earls-abstract.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cee.cornell.edu/people/profile.cfm?netid=cje23">Christopher Earls</a>
    (CEE, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    06 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-03-vt-am-colloq.html">Numerous Results Related to m-ary Partitions</a>
    <!-- <a href="/talks/2014-10-03-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/oct03.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.personal.psu.edu/jxs23/">James Sellers</a>
    (Penn State)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    03 Oct 2014
  </p>
  <div class="blurb"> 
  <p>The focus of this talk will be on arithmetic properties satisfied by various
integer partition functions. I will share some history, starting with
Ramanujan’s groundbreaking work in the 1910’s on the unrestricted partition
function p(n) and moving rapidly to work by Robert Churchhouse in the late
1960’s on the binary partition function. I will also discuss work of Oystein
Rodseth, George Andrews, and Hansraj Gupta in the 1970’s on results for m-ary
partitions which are natural generalizations of binary partitions. (An m-ary
partition of a positive integer n is a nonincreasing sequence of powers of m
which sum to n.) I will then discuss work I completed with Rodseth which
generalizes the results of Andrews and Gupta from the 1970’s. I will discuss a
set of “applications” of m-ary partitions to Neil Sloane’s questions on
non-squashing stacks of boxes, and then I will close by discussing recent (and
unexpected) results obtained with George Andrews and Aviezri Fraenkel on the
characterization of the number of m-ary partitions of n modulo m.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-03-cornell-cam.html">On Georg Duffing: Duffing’s Equation and Associated Phenomena</a>
    <!-- <a href="/talks/2014-10-03-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_ivana_kovacic_novi_sad_serbia_-_on_georg_duffing_duffings_equation_and_associated_phenomena"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.ivanakovacic.rs/">Ivana Kovacic</a>
    (Novi Sad, Serbia)<br/>
    
    Cornell Applied Math Colloquium,
    
    03 Oct 2014
  </p>
  <div class="blurb"> 
  <p>The Duffing equation is a nonlinear second-order differential equation with
cubic geometric nonlinearity. This equation is named after Georg Duffing, a
German engineer, who published a comprehensive book ‘Forced oscillations with
variable natural frequency and their technical significance’ in 1918. Since
then, there has been a tremendous amount of work done on this equation and its
various forms, including the development of different methods to investigate
the associated dynamic behaviour and characteristic phenomena.</p>

<p>The aim of this lecture is twofold. The first is to give a historical
background to Duffing’s work and life, as not much is known about him. The
story behind this is very interesting, because Georg Duffing was not an
academic; he was an engineer, who carried out academic work in his spare time.
The second aim is related to some of the phenomena occurring in Duffing
oscillators. The dynamics of the unforced, undamped Duffing oscillator involves
a relationship between the amplitude of vibration of a typical periodic motion
and its frequency/period. A graphical representation of this relation is called
a backbone curve. The backbone curve of Duffing oscillators is bent either to
the right or to the left, which causes hysteresis and jump phenomena in the
forced equation. There may be some situations where the jump phenomenon is
undesirable. This leads us to the question of designing a differential equation
which is similar to the Duffing equation, but for which the backbone curve is a
straight vertical line, corresponding thus to an amplitude-independent
frequency/period. We answer this question both by modifying the classical
Duffing restoring force and by using another approach in which the classical
Duffing restoring force stays in its original form.</p>


  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-02-stanford-la-opt.html">Mathematical Programming Methods for Large-scale Structural Topology Optimization</a>
    <!-- <a href="/talks/2014-10-02-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://orbit.dtu.dk/en/persons/susana-rojas-labanda(12a1ac99-1181-4a52-a12b-5bd6a949bac5).html">Susana Rojas Labanda (and Mathias Stolpe)</a>
    (Dept of Wind Energy, Technical University of Denmark, Roskilde, Denmark)<br/>
    
    Stanford LA/OPT Seminar,
    
    02 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Structural topology optimization is a relatively new but rapidly
expanding field because of its interesting theoretical implications in
mathematics, mechanics, and computer science, and its important
practical applications in the manufacturing and aerospace industries.</p>

<p>Topology optimization determines the optimal distribution of material
in a prescribed design domain.  The domain is often discretized by
finite elements, with the variables representing the density of each
element.  A common example is maximizing the stiffness of the structure
while satisfying a volume constraint and equilibrium equations <a href="http://www.worldcat.org/title/topology-optimization-theory-methods-and-applications/oclc/851393268">2</a>.</p>

<p>While a variety of large-scale nonlinear solvers could be applied,
structural topology optimization problems are usually solved by
sequential convex approximation methods such as the Method of Moving
Asymptotes (MMA) <a href="http://dx.doi.org/10.1002/nme.1620240207/">1</a>. This method was specially designed for use
within optimal design and is now extensively used in commercial
optimal design software as well as academic research codes. However,
it is a first-order method with slow convergence rates.</p>

<p>A large set of test problems has now been gathered, along with
extensive results for different solvers.  Performance profiles compare
the special-purpose first-order methods with some general-purpose
solvers such as FMINCON, IPOPT, and SNOPT, confirming that the use of
second-order information leads to better designs more efficiently than
the classical structural optimization solvers.</p>

<p>Given the performance profiles, a sequential quadratic programming
method SQP+ has been developed based on the algorithm explained in <a href="http://dx.doi.org/10.1093/imanum/drq037">3</a>.
Two phases, an inequality and an equality phase, are combined to produce
faster convergence.  Both phases use second-order information and
problem-specific characteristics to improve the efficiency of the solver.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-01-ucb-lapack.html">Finding the sparse representation of a dense matrix</a>
    <!-- <a href="/talks/2014-10-01-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSC_2014-10-01.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://math.berkeley.edu/~linlin/">Lin Lin</a>
    (UC Berkeley and LBNL)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    01 Oct 2014
  </p>
  <div class="blurb"> 
  <p>Let $\Psi$ be a unitary, dense matrix of size m<em>n (m»n).  The
$\varepsilon$-sparse representation of $\Psi$ means that there is a matrix
$\Phi$ of size m</em>n such that each column of $\Phi$ is sparse, $C$ is an n*n
invertible matrix, and $||\Psi-\Phi C||&lt;\varepsilon$.  In quantum physics, the
existence of such sparse representation explains why many chemical systems
exhibit local characters.  In this talk we discuss some existing numerical
techniques for finding such functions which originate from quantum physics
literature.  From a numerical linear algebra perspective, we introduce a new
technique called the selected columns of the density matrix (SCDM), which finds
such representation efficiently through a rank revealing QR procedure.
Generalization for the case when $\Psi$ is not unitary will also be discussed.</p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-01-temple-am.html">Convergence of Nonstatinary Iterative Methods for Singular Linear Equations with Index One</a>
    <!-- <a href="/talks/2014-10-01-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.YJZhou.1Oct14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://course.shufe.edu.cn/jpkc/jcjx/emaths/ezjy.htm">Jieyong Zhou</a>
    (Shanghai University of Finance and Economics)<br/>
    
    Temple Applied Math Seminar,
    
    01 Oct 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-">
  <h3 class="content-subhead">
    <a href="/talks/2014-10-01-stanford-la-opt.html">Dynamic Optimal Algorithms for Online Linear Programming</a>
    <!-- <a href="/talks/2014-10-01-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://web.stanford.edu/~yyye/">Yinyu Ye</a>
    (Management Science & Engineering, Stanford University)<br/>
    
    01 Oct 2014
  </p>
  <div class="blurb"> 
  <p>A natural optimization model that formulates many online resource
allocation and revenue management problems is the online linear
program (LP) where the constraint matrix, along with the objective
coefficients, are revealed column by column. We discuss optimal
algorithms for solving this surprisingly general class of online
problems under the assumption of random order of arrival and some
conditions on the data and size of the problem. These algorithms have
a feature of “learning while doing” by dynamically updating a
threshold price vector at certain time intervals, where the dual
prices learned from revealed columns in the previous period are used`
to determine the sequential decisions in the current period.
In particular, the algorithms don’t assume any distribution information
on the input itself, thus it is robust to data uncertainty and
variations due to its dynamic learning capability. Applications
include many online multi-resource allocation and multi-product
revenue management problems such as online routing and packing,
online combinatorial auctions, display advertising, etc.</p>


  </div>
</div>

<div class="series-ncsu-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-30-ncsu-amc.html">Active control of electromagnetic fields</a>
    <!-- <a href="/talks/2014-09-30-ncsu-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2494"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.uh.edu/~onofrei/">Daniel Onofrei</a>
    (University of Houston)<br/>
    
    NCSU Applied Math Seminar,
    
    30 Sep 2014
  </p>
  <div class="blurb"> 
  <p>In this talk we will discuss the problem of control of electromagnetic fields
by using active sources (antennas), i.e., characterization of surface currents
needed on the active sources so that their radiated fields will approximate
desired patterns in several given disjoint external regions. Mentioning that
any realistic design will need to consider a series of important feasibility
constraints, this problem can be placed at the intersection of several exciting
research areas: inverse source problems, optimal control of PDEs, antenna
synthesis and optimization theory.</p>

<p>In the first part of the talk, after a brief introduction of the subject, we
will discuss the problem of controlling transverse normal modes in a wave
guide. We will present our analytical approach, discuss the feasibility of the
approach and conclude with several relevant numerical results. Our analysis
indicates, among other things, that the proposed control strategy seems to be
feasible only in the near field region of the defending antenna.</p>

<p>In the second part of the lecture we will present the extension of our results
to the case of free space electromagnetics, discuss the feasibility of the
approach in this general context, and highlight several future research goals
and the challenges we anticipate for this project.</p>

  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-29-cornell-scan.html">From Data to Dynamics: Periodic Orbits.</a>
    <!-- <a href="/talks/2014-09-29-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-guckenheimer-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.cornell.edu/~gucken/">John Guckenheimer</a>
    (Math, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    29 Sep 2014
  </p>
  <div class="blurb"> 
  <p>The physical sciences derive “first prinicples” models for many phenomena
and then try to fit these models to observational data. Fitting procedures
need further development when the data come from time series measurements
of dynamical behavior. Systems that lack good models are even more
problematic. This talk will discuss “data driven” models of motion capture
data of cockroach and human running. Floquet theory is used formulate simple
models for the dynamics near a stable periodic orbit, and these are fit to
the data taking into account stochastic fluctuations. The analysis leads us
to pose mathematical questions about how much data is required to produce
accurate estimates for the parameters of a stochastic system.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-26-vt-am-colloq.html">Mathematical models of hepatitis B infections</a>
    <!-- <a href="/talks/2014-09-26-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/sep26.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.vt.edu/people/stanca/">Stanca Ciupe</a>
    (Virginia Tech)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    26 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Infection with hepatitis B virus results in acute hepatitis followed by
recovery in most human adults and in chronic hepatitis in non-vaccinated
infants. It is believed that the dynamical interactions between the virus and
the immune system can explain the infection outcome. We developed mathematical
models for the virus-host interactions in human adults and made predictions on
the mechanisms leading to viral clearance or persistence. This talk will focus
on the modeling process, the stability analysis of the corresponding systems of
differential equations, and the fitting of the models to human data. Our
results suggest that transition from acute to chronic disease can be explained
by a bi-stable switch and we will discuss the hypotheses leading to such
bifurcations. Lastly, we will present the additional challenges in inducing
viral clearance in infants by modeling the strategies that the virus employ to
escape the recognition of an immature immune system.</p>


  </div>
</div>

<div class="series-manchester-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-26-manchester-nas.html">Computational Tools for PDEs with Random Coefficients</a>
    <!-- <a href="/talks/2014-09-26-manchester-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.maths.manchester.ac.uk/our-research/events/seminars/numerical-analysis-and-scientific-computing/computational-tools-for-pdes-with-random-coefficients.htm"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://people.bath.ac.uk/eu204/">Elisabeth Ullmann</a>
    (University of Hamburg)<br/>
    
    Manchester Numerical Analysis Seminar,
    
    26 Sep 2014
  </p>
  <div class="blurb"> 
  <p>The simulation and forecast of complex physical processes in science,
engineering and industry requires input data which are often subject to
considerable uncertainties. This is due to incomplete models, measurement
errors or lack of knowledge. Partial differential equations (PDEs) with random
coefficients offer the opportunity to incorporate data uncertainties in
mathematical models and subsequent computer simulations. However, these PDEs
are formulated in a physical domain coupled with a possibly high-dimensional
sample space generated by random parameters and can be very
computing-intensive.</p>

<p>We outline the key computational challenges by discussing a model elliptic PDE
of single phase subsurface flow in a random porous medium. Suggested by
real-world data the diffusion coefficient is modeled as a lognormal random
field with rough realisations. Hence a large number of random parameters is
required. To date, only Monte Carlo based methods are computationally feasible
in this case, however the cost of Monte Carlo is often prohibitively large. We
employ multilevel Monte Carlo (MLMC), a novel variance reduction technique
which can reduce the cost significantly. We explain the basic MLMC idea and
combine this technique with mixed finite element discretisations to calculate
travel times of particles in groundwater flows (Graham et al., preprint).</p>

<p>For coefficients which can be parameterised by a small number of random
variables we employ spectral stochastic Galerkin (SG). A standard SG
discretisation of lognormal diffusion problems gives a block-dense Galerkin
matrix with sparse blocks. This precludes the development of iterative solvers
with optimal complexity from the outset. An alternative problem formulation as
convection-diffusion-type problem with random convective velocity has been
studied in (Ullmann et al., 2012). We discuss possible mixed formulations of
this problem. The saddle point Galerkin matrices are sparse, but have
nonsymmetric off-diagonal blocks. We suggest block-diagonal and
block-triangular preconditioners for use with GMRES and report on the
efficiency of the preconditioners.</p>

<h2 id="references">References</h2>

<ol>
  <li>I.G. Graham, R. Scheichl, and E. Ullmann. Mixed Finite Element Analysis of Lognormal Diffusion and Multilevel Monte Carlo Methods. Available from arXiv:1312.6047</li>
  <li>E. Ullmann, H.C. Elman, and O. G. Ernst. Efficient iterative solvers for stochastic Galerkin discretizations of log-transformed random diffusion problems. SIAM J. Sci. Comput., 34:A659-A682, 2012.</li>
</ol>


  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-26-cornell-cam.html">Revenue Management Under Markov Chain Choice Model</a>
    <!-- <a href="/talks/2014-09-26-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_huseyin_topaloglu_cornell_orie_-_revenue_management_under_markov_chain_choice_model"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://people.orie.cornell.edu/huseyin/">Huseyin Topaloglu</a>
    (Cornell ORIE)<br/>
    
    Cornell Applied Math Colloquium,
    
    26 Sep 2014
  </p>
  <div class="blurb"> 
  <p>A recent choice model is based on modeling the customer choice process through
a Markov chain. In this choice model, a customer arrives into the system with
the intention of purchasing a particular product. If this product is available
for purchase, then the customer purchases it and leaves the system. Otherwise,
the customer transitions to another product according to a Markov chain and
considers purchasing the other product. In this way, the customer transitions
between the products until she reaches a product that is available for purchase
or she decides to leave the system without purchasing anything. In this talk,
we consider revenue management problems when customers choose according to the
Markov chain choice model. For single-leg revenue management, we study the
dynamic programming formulation of the problem. We show that the efficient
offer sets are nested and the optimal policy can be characterized by nested
protection levels. For network revenue management, we study a deterministic
linear program that offers each subset of products with a certain probability.
In the deterministic linear program, there is one decision variable for each
subset of products. Thus, the number of decision variables grows exponentially
fast with the number of products, and it is common to solve the deterministic
linear program through column generation. We show that if the customers choose
according to the Markov chain choice model, then the deterministic linear
program can immediately be reduced to an equivalent one whose numbers of
decision variables and constraints grow only linearly with the number of
products. Finally, we discuss how to estimate the parameters of the Markov
chain choice model from past purchase history.</p>

<p>This work is joint with Jacob Feldman and Serdar Simsek.</p>


  </div>
</div>

<div class="series-stanford-la-opt">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-25-stanford-la-opt.html">Laplace inversion of LR-NMR relaxometry data using sparse representation methods</a>
    <!-- <a href="/talks/2014-09-25-stanford-la-opt.html"><i class="fa fa-plus-square"></i></a> -->
    
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://snow.stanford.edu/~levi/">Ofer Levi</a>
    (Dept of Industrial Engineering and Management, Ben-Gurion University of the Negev)<br/>
    
    Stanford LA/OPT Seminar,
    
    25 Sep 2014
  </p>
  <div class="blurb"> 
  <p>LR-NMR relaxometry is a powerful tool that can be harnessed for characterizing
constituents in complex materials.  The technology is used for industrial
quality control to measure solid-to-liquid and oil-to-water ratios in materials
as diverse as oil-bearing rock, food emulsions, and plant seeds.</p>

<p>Conversion of the relaxation signal into a continuous distribution of
relaxation components is an ill-posed problem.  We provide a numerical
optimization method for analyzing LR-NMR data by including L1 regularization
and applying the convex optimization solver PDCO.  Our integrated approach
includes validation of analyses by simulations, testing repeatability of
experiments, and validation of the model and its statistical assumptions.  The
method provides better resolved and more accurate solutions than those
suggested by existing tools.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-24-ucb-lapack.html">On Self-Convexity</a>
    <!-- <a href="/talks/2014-09-24-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-09-24.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.labma.ufrj.br/~gregorio/">Gregorio Malajovich</a>
    (Universidade Federal do Rio de Janeiro)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    24 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Numerical analysis has a rich story of interplay between two definitions of the
condition number: analytic and geometric. The analytic condition  number is the
norm of the derivative of the solution with respect to the coefficients. The
geometric condition number is the reciprocal distance to the set of ill-posed
instances. For instance, the Eckart-Young theorem says that for affine equation
solving or least squares, those definitions are the same.</p>

<p>Self-convexity is an attempt to encompass some of the convex geometric
properties of condition numbers in general. It was motivated by an attack to
Smale’s 17-th problem, which deals with systems of polynomial equations.
However, the results obtained so far are still limited to affine systems.</p>

<p>The objective of this talk is to present the basic ideas, results and
motivations. Much of this subject is still wide open, so there may be more
questions than theorems.</p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-24-temple-am.html">Computational Challenges of Homogenization</a>
    <!-- <a href="/talks/2014-09-24-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.Vladimirsky.24Sep14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.cornell.edu/~vlad/">Alexander Vladimirsky</a>
    (Cornell University)<br/>
    
    Temple Applied Math Seminar,
    
    24 Sep 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-mit-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-22-mit-amc.html">Toward the Scalable Inversion of Structured Matrices with Standard Admissibility Conditions</a>
    <!-- <a href="/talks/2014-09-22-mit-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www-math.mit.edu/amc/fall14/poulson.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://web.stanford.edu/~poulson/">Jack Poulson</a>
    (Stanford University)<br/>
    
    MIT Applied Math Colloquium,
    
    22 Sep 2014
  </p>
  <div class="blurb"> 
  <p>This presentation focuses on the numerical methods developed by our research
group for the simulation of incompressible stratified flows. In addition, the
application of these methods to the investigation of stratified flow processes
beneath the surfaces of the ocean and lakes, namely the interplay between
internal gravity waves and turbulence, will be discussed. Following an
introduction to the environmental importance of such fascinating phenomena, I
will elaborate on the suitability of element-based high-accuracy techniques for
their study. An introduction to the fundamentals of these techniques will then
be given. Example results from three select studies, relying on a spectral
multidomain penalty method (SMPM)-based flow solver, will be shown. Emphasis
will be placed on physical insights gained and the logistics involved with
running large simulations and managing and analyzing the large datasets they
produce. The challenges involved in extending the current version of our
SMPM-solver to accommodate more complex geometries and boundary conditions will
finally be discussed. The emphasis of this final discussion will be on the
design of an efficient parallel solver for the pressure Poisson equation to be
used for the study of highly non-hydrostatic phenomena in high-aspect ratio
domains.</p>

  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-22-cornell-scan.html">Hope for the best, prepare for the worst: optimal path planning under uncertainty.</a>
    <!-- <a href="/talks/2014-09-22-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-vladimirsky-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.cornell.edu/~vlad/">Alex Vladimirsky</a>
    (Math, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    22 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Practical optimal control problems involve uncertainty, which often has 
stochastic characterization. Canonical dynamic programming yields 
Hamilton-Jacobi PDEs for optimizing either the “average” or the “worst” 
case scenario. I will describe several models for optimizing the former 
subject to guarantees on the latter. We will also discuss semi-Lagrangian 
and Eulerian numerical schemes for the resulting augmented PDEs. 
The emphasis of the talk will be on the computational consequences of 
modeling assumptions.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-19-vt-am-colloq.html">String Compactification and Geometry</a>
    <!-- <a href="/talks/2014-09-19-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/sep19.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.phys.vt.edu/people/anderson.shtml">Lara Anderson</a>
    (Virginia Tech, Physics)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    19 Sep 2014
  </p>
  <div class="blurb"> 
  <p>I will provide an overview of compactification in string theory and the way in
which the structure of the physical theory is intrinsically intertwined with
questions in differential and algebraic geometry. In particular, I will
highlight the way in which string theory links the structure of diverse moduli
spaces in subtle and often powerful ways. This includes relationships between
moduli spaces and deformation problems of higher rank sheaves over 3-(complex)
dimensional Calabi-Yau threefolds and the geometry of 4-dimensional Calabi-Yau
manifolds, as well as hidden connections between the Calabi-Yau and Hitchin
integrable systems.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-19-cornell-cam.html">Designing Optimal Spectral Filters and Low-Rank Matrices for Inverse Problems</a>
    <!-- <a href="/talks/2014-09-19-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_julianne_chung_virginia_tech_-_designing_optimal_spectral_filters_and_low-rank_matrices_for_inverse_problems"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.vt.edu/people/jmchung/">Julianne Chung</a>
    (Virginia Tech)<br/>
    
    Cornell Applied Math Colloquium,
    
    19 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Computing reliable solutions to inverse problems is important in many
applications such as biomedical imaging, computer graphics, and security.
Regularization by incorporating prior knowledge is needed to stabilize the
inversion process. In this talk, we develop a new framework for solving inverse
problems that incorporates probabilistic information in the form of training
data. We provide theoretical results for the underlying Bayes risk minimization
problem and discuss efficient approaches for solving the associated empirical
Bayes risk minimization problem. Various constraints can be imposed to deal
with large-scale problems.  Here we describe methods for computing optimal
spectral filters, for cases where the SVD is available, and methods for
computing an optimal low-rank regularized inverse matrix, for cases where the
forward model is not known.</p>

<p>This is joint work with Matthias Chung (Virginia Tech) and Dianne O’Leary
(University of Maryland, College Park).</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-17-ucb-lapack.html">Bounds on the Energy Consumption of Computational Kernels</a>
    <!-- <a href="/talks/2014-09-17-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/SCaMCS_2014-09-17.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.eecs.berkeley.edu/~agearh/">Andrew Gearhart</a>
    (UC Berkeley)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    17 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Motivated by the large and increasingly growing dominant cost (in time and
energy) of moving data, algorithmic improvements have been attained by proving
lower bounds on the data movement required to solve a computational problem,
and then developing communication-optimal algorithms that attain these bounds.
This thesis extends previous research on communication bounds by presenting
bounds on the energy consumption of a large class of algorithms. These bounds
apply to sequential, distributed parallel and heterogeneous machine models and
are extensible to larger classes of machines.  We argue that the energy
consumption of many algorithms is predictable and can be modeled via linear
models with a handful of terms. Given energy bounds, we analyze the
implications of such results under additional constraints, such as an upper
bound on runtime, and also suggest directions for future research that may aid
future development of a hardware/software co-tuning process. We believe that
combining our bounds with other models of energy consumption may provide a
useful method for such co-tuning; i.e. to enable algorithm and hardware
architects to develop provably energy-optimal algorithms on customized hardware
platforms. </p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-17-temple-am.html">Interactive Treatment Planning in Cancer Radiotherapy</a>
    <!-- <a href="/talks/2014-09-17-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.Abebe.17Sep14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    Abraham Abebe
    
    (Temple University)<br/>
    
    Temple Applied Math Seminar,
    
    17 Sep 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-ncsu-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-16-ncsu-amc.html">Recent developments on reduced-order methods for high-dimensional kinetic equations</a>
    <!-- <a href="/talks/2014-09-16-ncsu-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.ncsu.edu/~gremaud/daniele.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.dam.brown.edu/people/venturi/Home.htm">Daniele Venturi</a>
    (Brown)<br/>
    
    NCSU Applied Math Seminar,
    
    16 Sep 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-ncsu-nas">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-15-ncsu-nas.html">The Modified Rayleigh-Benard Convection Problem and its Application to Greenhouse Gas Emissions Simulation</a>
    <!-- <a href="/talks/2014-09-15-ncsu-nas.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2449"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="https://faculty.utah.edu/u0851393-Ivan_Sudakov/research/index.hml">Ivan Sudakov</a>
    (University of Utah)<br/>
    
    NCSU Numerical Analysis Seminar,
    
    15 Sep 2014
  </p>
  <div class="blurb"> 
  <p>The original Rayleigh-Benard convection is a standard example of the system
where bifurcations occur with changing of a control parameter. I will discuss
the modified Rayleigh-Benard convection problem which includes the radiative
effects as well as the specific gas sources on a surface. Such formulation of
this problem leads to identification a new kind of bifurcation phenomenon,
besides the well-known Benard cells.</p>

<p>Modeling of greenhouse gas emissions into the atmosphere drives to difficult
problems, involving the Navier-Stokes equations. There exist climate models
with different levels of realism. Usually, one investigates these models by
computer simulations. However, it is difficult to the estimate reliability of
these computations, since it is connected with a complex mathematical problem
on the structural stability of attractors. Taking into account the modified
Rayleigh-Benard convection problem, I will discuss a new approach which makes
the problem of a climate catastrophe in the result of a greenhouse effect more
mathematically tractable and allows us to describe catastrophic bifurcations in
the atmosphere induced by soil greenhouse gas sources.</p>


  </div>
</div>

<div class="series-cornell-scan">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-15-cornell-scan.html">RBF interpolation with bound constraints</a>
    <!-- <a href="/talks/2014-09-15-cornell-scan.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.cornell.edu/~scan/f14-bindel-abstract.html"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.cs.cornell.edu/~bindel/">David Bindel</a>
    (CS, Cornell)<br/>
    
    Cornell Scientific Computing and Numerics Seminar,
    
    15 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Radial basis function (RBF) interpolation is a popular approach to
 fitting a function with given values at scattered sample points. In
 this talk, we describe how to compute RBF interpolants with given
 function values at some sample points and satisfying upper and lower
 bound constraints at other points. Our approach is based on a
 constrained quadratic minimization problem that leads to a unique,
 parsimonious interpolant in which RBF centers appear only as
 they are needed to enforce an equality or inequality constraint.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-12-vt-am-colloq.html">An Overview of Interpolatory Model Reduction</a>
    <!-- <a href="/talks/2014-09-12-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/sep12.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.vt.edu/people/beattie/">Chris Beattie</a>
    (Virginia Tech)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    12 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Dynamical systems form the basic modeling framework for an enormous variety of
complex phenomena. Direct numerical simulation of the correspondingly complex
dynamical systems is one of few means available for accurate prediction of the
associated physical phenomena. However, the ever increasing need for improved
accuracy requires the inclusion of ever more detail in the modeling stage,
leading inevitably to ever larger-scale, ever more complex dynamical systems
that must be simulated. Simulations in such large-scale settings can be
overwhelming and make unmanageably large demands on computational resources;
this is the main motivation for model reduction, which has as its goal
production of much simpler dynamical systems retaining the same essential
features of the original systems (high fidelity emulation of input/output
response and conserved quantities, preservation of passivity, etc).</p>

<p>I will give a brief overview of the objectives and methodology of model
reduction, focussing eventually on interpolatory projection methods that are
both simple and capable of providing nearly optimal reduced models in many
circumstances. Interpolatory methods provide a framework for model reduction
that allows retention of special structure such as parametric dependence,
port-Hamiltonian structure, internal delays, and connectivity of infinite
dimensional subsystems. I will describe recent work that is representative of
these developments and offer some open problems to meditate on.</p>


  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-12-cornell-cam.html">Online Transient Stability Assessment of Practical  Large-Scale Power Systems: Theory, Methodology  and Field Installations</a>
    <!-- <a href="/talks/2014-09-12-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_hsiao-dong_chiang_cornell_ece_-_online_transient_stability_assessment_of_practical_large-scale_power_systems_theory_methodology_and_field_installations"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://people.ece.cornell.edu/chiang/">Hsiao-Dong Chiang</a>
    (Cornell ECE)<br/>
    
    Cornell Applied Math Colloquium,
    
    12 Sep 2014
  </p>
  <div class="blurb"> 
  <p>For many utilities around the world, there has been considerable pressure to
increase power flows over existing transmission corridors. This consistent
pressure has prompted the requirement for extending current energy management
systems (EMS) to perform on-line transient stability assessment (TSA) and
control. Such extension, however, is a rather difficult task and requires
several break¬throughs in analysis tools, computation methods and control
schemes.</p>

<p>Indeed, online TSA, concerned with power system stability/instability after
contingencies, requires the handling of a large set of nonlinear differential
equations in addition to the nonlinear algebraic equations involved in the
static security assessment. TSA is designed to provide power system operators
with critical information including, (i) transient stability subject to a list
of contingencies and (ii) available (power) transfer limits at key interfaces
subject to transient stability constraints. The PJM Interconnection, one of the
largest utility in the world, has successfully designed and implemented a TSA
system. TEPCO-BCU was selected as the leading fast screening tool for improving
the performance of the PJM TSA system.</p>

<p>This talk will cover mathematical problem formulation, theoretical foundation,
and the BCU method and demonstrate one practical application of the
theory-based BCU method on the PJM interconnection system, a 14,000-bus power
system dynamic model with a list of 3000 contingencies, with practical data in
an on-line environment. This confirms the author’s belief that theory-based
solution methods can lead to practical applications in large-scale nonlinear
systems such as power systems.</p>


  </div>
</div>

<div class="series-ucb-lapack">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-10-ucb-lapack.html">Variations on LOBPCG</a>
    <!-- <a href="/talks/2014-09-10-ucb-lapack.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://math.berkeley.edu/~mgu/Seminar/Fall2014/MCaSCS_2014-09-10.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    Jed Duersch
    
    (UC Berkeley)<br/>
    
    Berkeley Matrix Computations Seminar,
    
    10 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Large sparse symmetric eigenvalue problems appear in a variety of research
fields. Due to the large dimensions of these problems, they are not tractable
with direct methods. Locally Optimal Block Preconditioned Conjugate Gradient is
an iterative method used to resolve a sample of extreme eigenvalues using BLAS3
block operations. We explore various implementations of this method as well as
ways to enhance its numerical stability. </p>


  </div>
</div>

<div class="series-temple-am">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-10-temple-am.html">Discontinuous Galerkin Finite Element Methods for Cahn-Hilliard Type Models</a>
    <!-- <a href="/talks/2014-09-10-temple-am.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://math.temple.edu/events/seminars/applied/abstracts/seminappl.Aristotelous.10Sep14.pdf"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://math.temple.edu/~aaristot">Andreas Aristotelous</a>
    (Temple University)<br/>
    
    Temple Applied Math Seminar,
    
    10 Sep 2014
  </p>
  <div class="blurb"> 
  

  </div>
</div>

<div class="series-ncsu-amc">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-08-ncsu-amc.html">Rational Krylov Approximation of Matrix Functions and Applications</a>
    <!-- <a href="/talks/2014-09-08-ncsu-amc.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="https://www.math.ncsu.edu/events/abstract.php?id=2464"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.guettel.com">Stefan Guettel</a>
    (Manchester)<br/>
    
    NCSU Applied Math Seminar,
    
    08 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Some problems in scientific computing, like the forward simulation of
electromagnetic waves in geophysical prospecting, can be solved via
approximation of f(A)b, the action of a large matrix function f(A) onto a
vector b. Iterative methods based on rational Krylov spaces are powerful tools
for these computations, and the choice of parameters in these methods is an
active area of research. We provide an overview of different approaches for
obtaining optimal parameters, with an emphasis on the exponential and resolvent
function, and the square root. If time permits, we will discuss a surprising
new application of the rational Arnoldi method for iteratively generating
near-optimal absorbing boundary layers for indefinite Helmholtz problems.</p>

  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-05-vt-am-colloq.html">Regularizing inverse problems by Krylov subspace methods</a>
    <!-- <a href="/talks/2014-09-05-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/sep05.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.unipd.it/~gazzola/">Silvia Gazzola</a>
    (Università di Padova)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    05 Sep 2014
  </p>
  <div class="blurb"> 
  <p>Inverse problems are ubiquitous in many areas of science and engineering: they
are typically modeled by Fredholm integral equations of the first kind, and the
available data are commonly affected by errors. Once continuous linear inverse
problems are discretized, they lead to ill-conditioned linear systems, often of
huge dimensions: regularization consists in replacing the original system by a
nearby problem with better numerical properties, in order to find a meaningful
approximation of the exact solution. In particular, we will focus on problems
involving the restoration of digital images corrupted by blur and noise.</p>

<p>During this talk we will introduce some standard regularization methods, both
direct and iterative. Among the direct ones, we will describe Tikhonov method;
among the iterative ones, we will describe some Krylov subspace methods based
on the Arnoldi algorithm, providing insight into their regularization
properties. Finally, we will introduce the most recent class of the
Arnoldi-Tikhonov methods, which merge a direct and an iterative approach to
regularization. The results of many numerical experiments will be shown, so to
compare the different methods and to contribute validating the newly-proposed
strategies.</p>


  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-09-05-cornell-cam.html">Robust Optimization in Electric Power System Operations</a>
    <!-- <a href="/talks/2014-09-05-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_andy_xu_sun_georgia_tech_-_robust_optimization_in_electric_power_system_operations"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www2.isye.gatech.edu/~xsun84/">Andy Xu Sun</a>
    (Georgia Tech)<br/>
    
    Cornell Applied Math Colloquium,
    
    05 Sep 2014
  </p>
  <div class="blurb"> 
  <p>This talk will present some recent advances of robust optimization in the
operation of electric power systems. In particular, we will discuss two-stage
and multistage adaptive robust optimization models and solution algorithms for
security-constrained unit commitment problems; we will also introduce new
modeling techniques using dynamic uncertainty sets and rolling-horizon adaptive
robust models for economic dispatch of power systems with high penetration
level of renewable energy resources.</p>


  </div>
</div>

<div class="series-vt-am-colloq">
  <h3 class="content-subhead">
    <a href="/talks/2014-08-29-vt-am-colloq.html">The Many Names of (7,3,1)</a>
    <!-- <a href="/talks/2014-08-29-vt-am-colloq.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://www.math.vt.edu/people/plinnell/Colloq14/aug29.php"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.math.vt.edu/people/ezbrown">Bud Brown</a>
    (Virginia Tech)<br/>
    
    Virginia Tech Applied Math Colloquium,
    
    29 Aug 2014
  </p>
  <div class="blurb"> 
  <p>Number theory, topology, graph colorings, projective geometry, combinatorial
designs, error-correcting codes, normed algebras, round-robin tournaments,
Hadamard matrices, sphere packings, finite fields, and orthogonal Latin squares
are all diverse and well-studied fields of mathematics. This talk is about
(7,3,1), an object that connects them all.</p>

  </div>
</div>

<div class="series-cornell-cam">
  <h3 class="content-subhead">
    <a href="/talks/2014-08-29-cornell-cam.html">Algorithmic Models of Market Equilibrium</a>
    <!-- <a href="/talks/2014-08-29-cornell-cam.html"><i class="fa fa-plus-square"></i></a> -->
    <a href="http://events.cornell.edu/event/cam_colloquium_yurii_nesterov_universite_catholique_de_louvain_-_algorithmic_models_of_market_equilibrium"><i class="fa fa-external-link-square"></i></a>
    <a class="toggler"><i class="fa fa-plus-square"></i></a>
  </h3>
  <p>
    <a href="http://www.uclouvain.be/32349.html">Yurii Nesterov</a>
    (Université catholique de Louvain)<br/>
    
    Cornell Applied Math Colloquium,
    
    29 Aug 2014
  </p>
  <div class="blurb"> 
  <p>In this talk, we suggest a new framework for constructing mathematical models
of market activity. Contrary to the majority of the classical economical models
(e.g. Arrow-Debreu, Walras, etc.), we get a characterization of general
equilibrium of the market as a saddle point in a convex-concave game. This
feature significantly simplifies the proof of existence theorems and
construction of the adjustment processes both for producers and consumers.
Moreover, we argue that the unique equilibrium prices can be characterized as a
unique limiting point of some simple price dynamics. In our model, the
equilibrium prices have natural explanation: they minimize the total excessive
revenue of the market’s participants. Due to convexity, all our adjustment
processes have unambiguous behavioral and algorithmic interpretation. From the
technical point of view, the most unusual feature of our approach is the
absence of the budget constraint in its classical form.</p>

  </div>
</div>



        </div>

        <div class="footer">
          <footer>
<div class="legal pure-g">
  <div class="pure-u-1-3"></div>
  <div class="pure-u-2-3">
    <p class="legal-copyright">
      &copy; 2014 David Bindel
    </p>
  </div>
</div>
</footer>

        </div>
        
    </div>

    <script src="js/ui.js"></script>
  </body>

</html>
