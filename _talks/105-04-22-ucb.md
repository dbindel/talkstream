---
title: Random and target-specific polynomial features for large-scale machine learning
speaker: Alex Gittens
speaker-affil: ICSI
date: 105-04-22 12:10:00
series: ucb-lapack
---

Random feature maps are a recent and popular paradigm that allow the training
of kernel machines with significantly decreased training and testing times; we
focus on the application of this paradigm to the case of polynomial kernels.

First, we observe that prior distributions proposed for polynomial feature maps
produce kernels that are rank-deficient compared to the exact polynomial
kernel, indicating that they produce redundant features. Based on this
observation, we propose compact random feature maps (CRAFTMaps), which allow
more accurate approximations of the polynomial kernel with fewer features. Our
experimental results are complemented with the first input-dimensionality
independent bounds on the number of random polynomial features (CRAFTMaps or
otherwise) needed to obtain element-wise accurate approximations to the
polynomial kernel matrix. 
